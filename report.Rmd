---
output:
  html_document:
    toc: true
    toc_float: false
  pdf_document:
    toc: true
params:
  input_prefix:
    value: ""
  annot_filename:
    value: "annotation.txt"
  sample_id:
    value: ""
  flipflop_summary:
    value: ""
---

---
title: "AAV Sequence Analysis"
subtitle: 'Sample: `r params$sample_id`'
date: 'Date: `r format(Sys.Date())`'
---

```{r setup, include=FALSE}
library(tidyverse)
library(grid)
library(gridExtra)

knitr::opts_chunk$set(echo=FALSE, fig.align="center", out.width="80%")
# Avoid scientific notation
options(scipen=999)
```


```{r sortorder, message=FALSE, warning=FALSE}
valid_types <- c('ssAAV', 'scAAV', 'host', 'repcap', 'helper', 'lambda', 'unmapped', 'chimeric')
valid_subtypes <- c('full', 'full-gap', 'left-partial', 'right-partial', 'wtITR-partial', 'mITR-partial', 'partial', 'backbone', 'vector+backbone')
```

```{r calculate, message=FALSE, warning=FALSE}
# read the annotation file to find the vector target region
#
#NAME=myHost;TYPE=host;
#NAME=myVector;TYPE=vector;REGION=1795-6553;
#NAME=mRepCap;TYPE=repcap;REGION=1895-5987;


TARGET_REGION_START <- 0
TARGET_REGION_END <- 0
TARGET_REGION_START_REPCAP <- 0
TARGET_REGION_END_REPCAP <- 0

annot <- read.table(params$annot_filename)
for (i in 1:dim(annot)[1]) {
    if (unlist(strsplit(annot[i,],';'))[2]=='TYPE=vector') {
        p <- unlist(strsplit(annot[i,],';'))[3];
        s_e <- as.integer(unlist(strsplit(unlist(strsplit(p, '='))[2], '-')));
        TARGET_REGION_START <- s_e[1];
        TARGET_REGION_END <- s_e[2];
    }
    else if (unlist(strsplit(annot[i,],';'))[2]=='TYPE=repcap') {
        p <- unlist(strsplit(annot[i,],';'))[3];
        s_e <- as.integer(unlist(strsplit(unlist(strsplit(p, '='))[2], '-')));
        TARGET_REGION_START_REPCAP <- s_e[1];
        TARGET_REGION_END_REPCAP <- s_e[2];
    }
}


x.all.summary <- read_tsv(paste0(params$input_prefix, '.summary.csv')) %>% mutate(map_start=map_start0,map_end=map_end1) %>% mutate(SampleID=params$sample_id,.before=read_id)
write_tsv(x.all.summary,str_c(c(params$input_prefix,".alignments.tsv"), collapse = ""))

x.all.err <- read_tsv(paste0(params$input_prefix, '.nonmatch_stat.csv.gz')) %>% mutate(SampleID=params$sample_id,.before=read_id)
x.all.read <- read_tsv(paste0(params$input_prefix, '.per_read.csv')) %>% mutate(SampleID=params$sample_id,.before=read_id)

x.all.err[x.all.err$type=='D',"type"] <- 'deletion'
x.all.err[x.all.err$type=='I',"type"] <- 'insertion'
x.all.err[x.all.err$type=='X',"type"] <- 'mismatch'
x.all.err[x.all.err$type=='N',"type"] <- 'gaps'

# ----------------------------------------------------
# produce stats for vector only (ssAAV or scAAV)
# ----------------------------------------------------
x.read.vector <- filter(x.all.read, assigned_type %in% c('scAAV', 'ssAAV'))
x.err.vector <- filter(x.all.err, read_id %in% x.read.vector$read_id)
x.summary.vector <- filter(x.all.summary, read_id %in% x.read.vector$read_id)


total_num_reads <- dim(x.read.vector)[1]

total_err <- dim(x.err.vector)[1]
x.err.vector$pos0_div <- (x.err.vector$pos0%/%10 * 10)
df.err.vector <- x.err.vector %>% group_by(pos0_div, type) %>% summarise(count=n())
x.err.vector$type_len_cat <- "1-10"
x.err.vector[x.err.vector$type_len>10, "type_len_cat"] <- "11-100"
x.err.vector[x.err.vector$type_len>100, "type_len_cat"] <- "100-500"
x.err.vector[x.err.vector$type_len>500, "type_len_cat"] <- ">500"
x.err.vector$type_len_cat <- ordered(x.err.vector$type_len_cat, levels=c('1-10', '11-100', '100-500', '>500'))
write_tsv(x.err.vector,str_c(c(params$input_prefix,".sequence-error.tsv"), collapse = ""))

df.err_len_cat.vector <- x.err.vector %>% group_by(type, type_len_cat) %>% summarise(count=n()) %>% mutate(freq=round(100*count/total_err, 2))

df.read_stat_N <- filter(x.err.vector,type=='gaps') %>% group_by(read_id) %>% summarise(max_del_size=max(type_len))
num_reads_large_del <- sum(df.read_stat_N$max_del_size>=200)
freq_reads_large_del <- round(num_reads_large_del*100/total_num_reads, 2)
df.read_stat_N_summary <- data.frame(category=c("Total Reads", "Reads with gaps >200bp"),
                           value=c(total_num_reads, paste0(num_reads_large_del, " (", freq_reads_large_del, "%)")))


ERR_SAMPLE_SIZE <- 50000
x.err2.vector <- x.err.vector[sample(1:dim(x.err.vector)[1], ERR_SAMPLE_SIZE),]
p1.err_dot <- ggplot(x.err2.vector, aes(x=pos0+1, y=type_len)) + geom_point(aes(color=type), alpha=0.5) +
               xlim(c(TARGET_REGION_START, TARGET_REGION_END)) +
               xlab("Reference Position") + ylab("Sub/Ins/Del Length") +
               labs(title="Distribution of Non-Matches", subtitle="Each point is a non-match from a read, only 50k points at most")

p1.err_dot_close <- ggplot(x.err2.vector, aes(x=pos0+1, y=type_len)) + geom_point(aes(color=type), alpha=0.5) +
               xlim(c(TARGET_REGION_START, TARGET_REGION_END)) +
               ylim(c(0, 100)) +
               xlab("Reference Position") + ylab("Sub/Ins/Del Length") +
               labs(title="Distribution of Non-Matches (of sizes <100 only)", subtitle="Each point is a non-match from a read, only 50k points at most")

p1.err_sub <- ggplot(filter(df.err.vector,type=='mismatch'), aes(x=pos0_div, y=count)) + geom_bar(fill='darkgreen', stat='identity') +
              xlim(c(TARGET_REGION_START, TARGET_REGION_END)) +
              labs(title="Distribution of Non-matches by Reference Position, Substitutions",
                   subtitle="Higher bars indicate hot spots for substitutions w.r.t reference") +
               xlab("Reference Position") + ylab("Frequency")

p1.err_del <- ggplot(filter(df.err.vector,type=='deletion'), aes(x=pos0_div, y=count)) + geom_bar(fill='darkred', stat='identity') +
              xlim(c(TARGET_REGION_START, TARGET_REGION_END)) +
              labs(title="Distribution of Non-matches by Reference Position, Deletions",
                   subtitle="Higher bars indicate hot spots for deletion w.r.t reference") +
               xlab("Reference Position") + ylab("Frequency")

p1.err_ins <- ggplot(filter(df.err.vector,type=='insertion'), aes(x=pos0_div, y=count)) + geom_bar(fill='darkblue', stat='identity') +
              xlim(c(TARGET_REGION_START, TARGET_REGION_END)) +
              labs(title="Distribution of Non-matches by Reference Position, Insertions",
                   subtitle="Higher bars indicate hot spots for insertion w.r.t reference") +
               xlab("Reference Position") + ylab("Frequency")

p1.map_iden <- ggplot(x.summary.vector, aes(map_iden*100, fill=map_subtype)) + geom_histogram(binwidth=0.01) +
               xlab("Mapping Identity (%)") + ylab("Read Count") +
               labs(title="Distribution of Mapped Identity to Reference")

p1.map_len <- ggplot(x.summary.vector, aes(map_len, fill=map_subtype)) + geom_histogram(aes(y=..count../sum(..count..))) +
               xlab("Mapped Reference Length") + ylab("Fraction of Reads") +
               labs(title="Distribution of Mapped Reference Spanning Region Size")

p1.map_starts <- ggplot(x.summary.vector, aes(map_start0+1, fill=map_subtype)) +
                geom_histogram(aes(y=..count../sum(..count..))) +
                geom_vline(xintercept=TARGET_REGION_START, color='red', lty=2) +
                geom_vline(xintercept=TARGET_REGION_END, color='red', lty=2) +
                xlab("Mapped Reference Start Position") + ylab("Fraction of Reads") +
                labs(title="Distribution of Mapped Reference Start Position")

p1.map_ends <- ggplot(x.summary.vector, aes(map_end1, fill=map_subtype)) +
                geom_histogram(aes(y=..count../sum(..count..))) +
                geom_vline(xintercept=TARGET_REGION_START, color='red', lty=2) +
                geom_vline(xintercept=TARGET_REGION_END, color='red', lty=2) +
                xlab("Mapped Reference End Position") + ylab("Fraction of Reads") +
                labs(title="Distribution of Mapped Reference End Position")


x.read.vector$subtype <- x.read.vector$assigned_subtype
x.read.vector[!x.read.vector$subtype %in% valid_subtypes, "subtype"] <- 'other'

p1.scAAV_len_hist <- ggplot(filter(x.read.vector, assigned_type=='scAAV'), aes(x=read_len, color=subtype)) +
                       geom_freqpoly() +
                       xlab("Read length (bp)") +
                       ylab("Count") +
                       labs(title="Distribution of read length, scAAV, by subtype")

p1.ssAAV_len_hist <- ggplot(filter(x.read.vector, assigned_type=='ssAAV'), aes(x=read_len, color=subtype)) +
                       geom_freqpoly() +
                       xlab("Read length (bp)") +
                       ylab("Count") +
                       labs(title="Distribution of read length, ssAAV, by subtype")

# ----------------------------------------------------
# produce stats for repcap (if exists)
# ----------------------------------------------------
x.read.repcap <- filter(x.all.read, assigned_type=='repcap')
#x.err.repcap <- filter(x.all.err, read_id %in% x.read.repcap$read_id)
x.summary.repcap <- filter(x.all.summary, read_id %in% x.read.repcap$read_id)

if (dim(x.read.repcap)[1] > 10) { # only plot if at least 10 reads
    p1.map_len.repcap <- ggplot(x.summary.repcap, aes(map_len, fill=map_subtype)) + geom_histogram(aes(y=..count../sum(..count..))) +
                   xlab("Mapped Reference Length") + ylab("Fraction of Reads") +
                   labs(title="Repcap: Distribution of Mapped Reference Spanning Region Size")

    p1.map_starts.repcap <- ggplot(x.summary.repcap, aes(map_start0+1, fill=map_subtype)) +
                    geom_histogram(aes(y=..count../sum(..count..))) +
                    geom_vline(xintercept=TARGET_REGION_START_REPCAP, color='red', lty=2) +
                    xlab("Mapped Reference Start Position") + ylab("Fraction of Reads") +
                    labs(title="Repcap: Distribution of Mapped Reference Start Position")

    p1.map_ends.repcap <- ggplot(x.summary.repcap, aes(map_end1, fill=map_subtype)) +
                    geom_histogram(aes(y=..count../sum(..count..))) +
                    geom_vline(xintercept=TARGET_REGION_END_REPCAP, color='red', lty=2) +
                    xlab("Mapped Reference End Position") + ylab("Fraction of Reads") +
                    labs(title="Repcap: Distribution of Mapped Reference End Position")
}

allowed_subtypes <- c('full', 'full-gap', 'vector+backbone')
p2.atype_violin <-ggplot(filter(x.read.vector, assigned_subtype %in% allowed_subtypes), aes(x=paste(assigned_type, assigned_subtype,sep='-'), y=read_len)) +
                    geom_violin() +
                    xlab("Assigned AAV Type") + ylab("Read Length") +
                    labs(title="Distribution of Read Lengths by Assigned AAV Type") +
                    theme(axis.text.x=element_text(angle = -45, hjust = 0))


p3.err_Ns <- ggplot(filter(df.err.vector,type=='gaps'), aes(x=pos0_div, y=count)) + geom_bar(fill='orange', stat='identity') +
              xlim(c(TARGET_REGION_START, TARGET_REGION_END)) +
              labs(title="Distribution of large deletion events (cigar 'N'), by position",
                   subtitle="Higher bars indicate hot spots for large deletions w.r.t reference") +
               xlab("Reference Position") + ylab("Frequency")

p3.err_size_Ns <- ggplot(df.read_stat_N, aes(max_del_size)) + geom_histogram(binwidth=100) +
                xlab("Maximum large deletion size") + ylab("Number of Reads") +
                labs(title="Distribution of biggest deletion for reads")

# ----------------------------------------------------
# produce stats for flip flop (if exists)
# ----------------------------------------------------

if (file.exists(params$flipflop_summary)) {
    data.flipflop <- read.table(params$flipflop_summary,sep='\t',header=T)
    df.flipflop <- data.flipflop %>% group_by(type, subtype, leftITR, rightITR) %>% summarise(count=n())
    scff <- filter(df.flipflop, type=='scAAV')
    ssff <- filter(df.flipflop, type=='ssAAV')
}
```

`\pagebreak`{=latex}

# Read type classification

![Single-stranded AAV types (ssAAV)](static/class_def_ssAAV.png)

![Self-complementary AAV types (scAAV)](static/class_def_scAAV.png)


## Definitions

Assigned Type|Definition
------------:|----------------------------------------------------
scAAV        |A read is self-complementary (scAAV) if it has both a primary and supplementary alignment to the vector genome.
ssAAV        |Read mapping to the AAV genome and is not self-complementary.
other        |Read consists of a fragment mapping to the vector but with unexpected polarities (e.g. +,-,- or +,+,+) and cannot be well-defined at the moment. Usually this means there are multiple supplementary alignments on the vector region or and it’s a weird molecule.
host         |Read originates from the host genome that is given (e.g. hg38, CHM13).
repcap       |Read originates from the repcap plasmid. The Rep gene encodes four proteins (Rep78, Rep68, Rep52, and Rep40), which are required for viral genome replication and packaging, while Cap expression gives rise to the viral capsid proteins (VP; VP1/VP2/VP3), which form the outer capsid shell that protects the viral genome, as well as being actively involved in cell binding and internalization.
helper       |Read originates from the helper plasmid. In addition to Rep and Cap, AAV requires a helper plasmid containing genes from adenovirus. These genes (E4, E2a and VA) mediate AAV replication.
chimeric     |Read consists of fragments that map to one or more “genomes” (e.g. vector and host; helper and repcap)

* Note that even though ssAAV distinguishes one ITR as the wildtype (wtITR) and the other as the mutated ITR (mITR) we will still refer to them as leftITR vs rightITR (so using “left-partial” which in this case would be equivalent to saying “mITR-partial” since the mITR is the left IT based on the genomic coordinates given here).


# Assigned Types By Read Alignment Characteristics

```{r render1, message=FALSE, warning=FALSE}
x.all.read[is.na(x.all.read$assigned_type), "assigned_type"] <- 'unmapped'
x.all.read[grep("|", as.character(x.all.read$assigned_type), fixed=T), "assigned_type"] <- 'chimeric'
x.all.read[!(x.all.read$assigned_type %in% valid_types), "assigned_type"] <- 'other'

#valid_subtypes <- c('full', 'full-gap', 'left-partial', 'right-partial', 'wtITR-partial', 'mITR-partial', 'partial', 'backbone', 'vector+backbone')
x.all.read[!(x.all.read$assigned_subtype %in% valid_subtypes), "assigned_subtype"] <- 'other'
write_tsv(x.all.read,str_c(c(params$input_prefix,".readsummary.tsv"), collapse = ""))
min_show_freq <- 0.01
total_read_count.all <- sum(x.all.read$effective_count) #dim(x.all.read)[1]
df.read1 <- x.all.read %>% group_by(assigned_type) %>%
       summarise(e_count=sum(effective_count)) %>% mutate(freq=round(e_count*100/total_read_count.all,2))
df.read1 <- df.read1[order(-df.read1$freq),]
df.read2 <- x.all.read %>% group_by(assigned_type, assigned_subtype) %>%
       summarise(e_count=sum(effective_count)) %>% mutate(freq=round(e_count*100/total_read_count.all,2))
df.read2 <- df.read2[order(-df.read2$freq),]

table.atype1 <- tableGrob(df.read1, rows = NULL, cols = c("Assigned Type", "Count", "Frequency (%)"))
title.atype1 <- textGrob("Assigned Types By Read Alignment Characteristics, overview", gp=gpar(fontface="italic", fontsize=15), vjust=-18)
gt.atype1 <- gTree(children=gList(title.atype1, table.atype1))
grid.arrange(gt.atype1)
```

```{r readtypesplot, message=FALSE, warning=FALSE}
countreads <- df.read1 %>% dplyr::filter(assigned_type != 'Lambda')

# Bar chart
ggplot(countreads,aes(x=assigned_type, y=freq, fill=assigned_type)) + geom_bar(stat='identity') + xlab("Sequence") + ylab("Percent of Reads")  +   theme_bw()

# Pie chart
ggplot(countreads, aes(x="", y=e_count, fill=assigned_type)) +  geom_bar(stat="identity", width=1) +  coord_polar("y", start=0) + theme_void()
```


## Single-Stranded vs Self-Complementary Frequency

```{r render3, message=FALSE, warning=FALSE}
# table.atype2 <- tableGrob(filter(df.read2,freq>=min_show_freq), rows = NULL,
#                 cols = c("Assigned Type", "Assigned Subtype", "Count", "Frequency (%)"),
#                 theme=ttheme_minimal(base_size = 8))
# title.atype2 <- textGrob("Assigned Types, detailed (>1% only)", gp=gpar(fontface="italic", fontsize=12), vjust=-18)
# gt.atype2 <- gTree(children=gList(title.atype2, table.atype2))
# grid.arrange(gt.atype2)

total_read_count.vector <- sum(x.read.vector$effective_count)
df.read.vector1 <- x.read.vector %>% group_by(assigned_type) %>%
     summarise(e_count=sum(effective_count)) %>% mutate(freq=round(e_count*100/total_read_count.vector,2))
df.read.vector1 <- df.read.vector1[order(-df.read.vector1$freq),]
df.read.vector2 <- x.read.vector %>% group_by(assigned_type, assigned_subtype) %>%
     summarise(e_count=sum(effective_count)) %>% mutate(freq=round(e_count*100/total_read_count.vector,2))
df.read.vector2 <- df.read.vector2[order(-df.read.vector2$freq),]
df.read.ssaav <-  dplyr::filter(df.read.vector2,assigned_type=='ssAAV') %>% filter(assigned_subtype=='full' | assigned_subtype=='right-partial'| assigned_subtype=='left-partial') %>% select(e_count) %>% as.data.frame()
total_ssaav <- sum(df.read.ssaav$e_count)
table.atype.vector1 <- tableGrob(df.read.vector1, rows = NULL, cols = c("Assigned Type",  "Count", "Frequency (%)"))
title.atype.vector1 <- textGrob("Assigned AAV Types By Read Alignment Characteristics, overview", gp=gpar(fontface="italic", fontsize=15), vjust=-18)
gt.atype.vector1 <- gTree(children=gList(title.atype.vector1, table.atype.vector1))
grid.arrange(gt.atype.vector1)
```

# Distribution of read lengths by assigned AAV types

```{r render4, message=FALSE, warning=FALSE}
grid.arrange(p2.atype_violin)
```

# Assigned AAV read types detailed analysis

## Assigned AAV Types

```{r render5, message=FALSE, warning=FALSE}
table.atype.vector2 <- tableGrob(df.read.vector2[1:20,], rows = NULL,
                     cols = c("Assigned Type, detailed", "Assigned Subtype", "Count", "Frequency (%)"),
                     theme=ttheme_minimal(base_size = 8))
title.atype.vector2 <- textGrob("Assigned AAV Types, detailed (top 20 only)", gp=gpar(fontface="italic", fontsize=12), vjust=-24)
gt.atype.vector2 <- gTree(children=gList(title.atype.vector2, table.atype.vector2))
grid.arrange(gt.atype.vector2)
```

### Definitions

Assigned SubType|Definition
---------------:|----------------------------------------------------------------
full            |Read consists of a DNA sequence which includes the entire ITR-to-ITR target vector sequence. Read is present in both (+) and (-) polarities.
left-partial    |Read consists of a fragment of the vector originating from the upstream (left ITR) of the vector while not covering the right ITR. Read is present in both (+) and (-) polarities.
right-partial   |Read consists of a fragment of the vector originating from the downstream (right ITR) of the vector while not covering the left ITR. Read is present in both (+) and (-) polarities.
partial         |Read consists of a fragment of the vector originating from within the ITR sequences. Read is present in both (+) and (-) polarities.
vector+backbone |Read consists of a fragment including the vector as well as plasmid backbone sequence. Read is present in both (+) and (-) polarities.
backbone        |Read consists of a fragment originating solely from the plasmid backbone sequence. Read is present in both (+) and (-) polarities.


# Flip/Flop considerations

Term|Definition
---:|----------------
Flip/Flop|One ITR is formed by two palindromic arms, called B–B' and C–C', embedded in a larger one, A–A'. The order of these palindromic sequences defines the flip or flop orientation of the ITR.


```{r flipflopscplot, message=FALSE, warning=FALSE, results='asis'}
if (exists("df.flipflop")) {
  ffplot <- df.flipflop %>% mutate(class=if_else(leftITR == 'unclassified' | rightITR == 'unclassified' | leftITR == 'unknown' | rightITR == 'unknown',"unclassifed",paste(leftITR,rightITR,sep='-'))) %>% group_by(type, subtype, class) %>% summarize(classct=sum(count)) %>% filter(subtype == 'vector-full')
ggplot(ffplot,aes(x=type,y=classct,fill = class)) + geom_bar(stat='identity') + labs(x='Assigned Type',y='Number of Reads') + theme(panel.grid.major = element_blank(),panel.grid.minor = element_blank(), panel.border = element_blank(),panel.background = element_blank())
}
```


## Flip/Flop configurations, scAAV only

```{r render6, message=FALSE, warning=FALSE}
### flip flop configurations (if applicable)
if (file.exists(params$flipflop_summary)) {
numssff <- sum(ssff$count)
if (is.numeric(numssff) & is.numeric(total_ssaav)) {
  if (total_ssaav > 0 & numssff > 0 & numssff*2 == total_ssaav) {
    ssff <-  ssff %>% mutate(count=count*2)
  }else {
    ssff <-  ssff %>% mutate(count=count)
  }
}
fftbl <- bind_rows(scff,ssff)
write_tsv(fftbl,str_c(c(params$input_prefix,".flipflop.tsv"), collapse = ""))
if (nrow(scff) > 1) {
  table.sc.flipflop <- tableGrob(scff, rows=NULL, cols=c("type","subtype","leftITR","rightITR","count"))
  title.sc.flipflop <- textGrob("Flip/Flop configurations, scAAV only", gp=gpar(fontface="italic", fontsize=15), vjust=-20)
  gt.sc.flipflop <- gTree(children=gList(title.sc.flipflop, table.sc.flipflop))
  grid.arrange(gt.sc.flipflop)
}
} else {
  cat("No flip/flop analysis results available to display.")
}
```


## Flip/Flop configurations, ssAAV only

```{r render7, message=FALSE, warning=FALSE}
if (file.exists(params$flipflop_summary)) {
if (nrow(ssff) > 1) {
  table.ss.flipflop <- tableGrob(ssff, rows=NULL, cols=c("type","subtype","leftITR","rightITR","count"))
  title.ss.flipflop <- textGrob("Flip/Flop configurations, ssAAV only", gp=gpar(fontface="italic", fontsize=15), vjust=-20)
  gt.ss.flipflop <- gTree(children=gList(title.ss.flipflop, table.ss.flipflop))
  grid.arrange(gt.ss.flipflop)
}
} else {
  cat("No flip/flop analysis results available to display.")
}
```


# Distribution of read length by subtype

## Distribution of scAAV read length by subtype

```{r render8, message=FALSE, warning=FALSE}
### scAAV and ssAAV length histogram
grid.arrange(p1.scAAV_len_hist)
```

## Distribution of ssAAV read length by subtype

```{r render9, message=FALSE, warning=FALSE}
grid.arrange(p1.ssAAV_len_hist)
```

# AAV Mapping to Reference Sequence

## Gene Therapy Construct

### Distribution of Mapped Reference Start Position

```{r render10, message=FALSE, warning=FALSE}
grid.arrange(p1.map_starts)
```

### Distribution of Mapped Reference End Position

```{r render11, message=FALSE, warning=FALSE}
grid.arrange(p1.map_ends)
```

### Distribution of Mapped Reference Spanning Region Size

```{r render12, message=FALSE, warning=FALSE}
grid.arrange(p1.map_len)
```

## RepCap

### Distribution of Mapped Reference Start Position

```{r render13, message=FALSE, warning=FALSE}
if (dim(x.read.repcap)[1] > 10) { # only plot if at least 10 reads
  grid.arrange(p1.map_starts.repcap)
} else {
  cat("Not enough RepCap-mapped reads available to plot.")
}
```

### Distribution of Mapped Reference End Position

```{r render14, message=FALSE, warning=FALSE}
if (dim(x.read.repcap)[1] > 10) { # only plot if at least 10 reads
  grid.arrange(p1.map_ends.repcap)
} else {
  cat("Not enough RepCap-mapped reads available to plot.")
}
```

### Distribution of Mapped Reference Spanning Region Size

```{r render15, message=FALSE, warning=FALSE}
if (dim(x.read.repcap)[1] > 10) { # only plot if at least 10 reads
  grid.arrange(p1.map_len.repcap)
} else {
  cat("Not enough RepCap-mapped reads available to plot.")
}
```


# Distribution of Non-matches by Reference Position

## Substitutions

```{r render16, message=FALSE, warning=FALSE}
grid.arrange(p1.err_sub)
```

## Deletions

```{r render17, message=FALSE, warning=FALSE}
grid.arrange(p1.err_del)
```

## Insertions

```{r render18, message=FALSE, warning=FALSE}
grid.arrange(p1.err_ins)
```


# Methods

This workflow can be used to characterize PacBio adeno-associated virus (AAV) products by examining alignment coverage across sequence regions of interest.
The input BAM file should be from the PacBio sequencer run in AAV mode, or equivalent circular consensus sequencing (CCS) reads (Travers et al., 2010).
Reads are aligned to the reference sequences using Minimap2 (Li, 2018).
Resulting alignments are filtered for quality to include primary alignments and reads with mapping quality scores greater than 10.
Finally, a custom report of alignment statistics is generated in HTML or PDF format.


## Citations

1. Travers, K. J., Chin, C.-S., Rank, D. R., Eid, J. S. & Turner, S. W. A flexible and efficient template format for circular consensus sequencing and SNP detection. Nucleic Acids Research 38, e159–e159 (2010).
2. Li, H. Minimap2: Pairwise alignment for nucleotide sequences. Bioinformatics 34, 3094–3100 (2018).


```{r saverdata, message=FALSE, warning=FALSE}
#save.image(file = paste0(params$input_prefix, ".Rdata"))
```
